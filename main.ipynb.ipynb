{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H0uhH1X3oL9"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Lembar Kerja MK ASD Kelas B TIF, Filkom UB</h1>\n",
        "\n",
        "**************************************\n",
        "Dosen Pengampu: Imam Cholissodin, S.Si., M.Kom. | imamcs@ub.ac.id | Fakultas Ilmu Komputer (Filkom), Universitas Brawijaya (UB) | Semester Genap 2021/2022 | Dibuat pada 1 Feb. 2020 | 22 Agustus 2021 | 8 Feb. 2022\n",
        "\n",
        "Semoga Bermanfaat. Aamiin :D\n",
        "**************************************\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3EInPeD3rW4",
        "outputId": "38084a40-be7f-47a2-a1c4-2560a531ef3b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ref:\n",
        "# [0] https://towardsdatascience.com/develop-a-nlp-model-in-python-deploy-it-with-flask-step-by-step-744f3bdd7776\n",
        "# [1] https://github.com/pemagrg1/NLP-Flask-Website\n",
        "# [2] https://stackoverflow.com/questions/46454542/how-do-i-get-the-words-that-are-not-in-the-lexicon-of-a-cfg-grammar\n",
        "# [3] etc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FP - Run Web App pada Google Colab. untuk ParseTree & Typo App"
      ],
      "metadata": {
        "id": "9ceDwGW1dX_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Clone resource gdrive & dari github"
      ],
      "metadata": {
        "id": "jAQn5rPCdDdh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBzybd-73_Go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b83c6a6-85ca-4926-fec2-efebd368f6a1"
      },
      "source": [
        "import os\n",
        "from google.colab import output\n",
        "os.chdir(\"/content/drive/My Drive\")\n",
        "path = \"#Pengajaran Genap 2021-2022/ASD For Me/MyApp/MyFP\"\n",
        "if not os.path.exists(path):\n",
        "  os.makedirs(path)\n",
        "  os.chdir(\"/content/drive/My Drive/\"+path)\n",
        "\n",
        "  # download Web App dasar\n",
        "  !gdown 1NFSfWCv_tLjSGwk6obznpvM1B6-UIml0\n",
        "  !tar -xv -C './' -f './SmartAppRev5.tar'\n",
        "  !mv ./SmartApp ./parsetree-search\n",
        "  !rm ./SmartAppRev5.tar\n",
        "\n",
        "  # download dok contoh yg didalamnya juga ada data kamus\n",
        "  !gdown 1D7BfntXyW3uXb88USLqiuDs_IIJx2FxH\n",
        "  !tar -xv -C './' -f './dok-contoh.tar'\n",
        "  !cp -f ./dok-contoh/* ./.\n",
        "  !rm ./dok-contoh.tar\n",
        "  !rm -r ./dok-contoh\n",
        "\n",
        "  os.makedirs(\"dok/pdfs\")\n",
        "  !mv ./dok_full.pdf ./dok/pdfs\n",
        "  !mv ./dok_full2.pdf ./dok/pdfs\n",
        "  os.makedirs(\"dok/txts\")\n",
        "\n",
        "  # import fileinput\n",
        "  # with fileinput.FileInput('./SmartApp/templates/index.html', inplace=True, backup='.bak') as file:\n",
        "  #   for line in file:\n",
        "  #       print(line.replace('Smart Data Application', 'My Data Application'), end='')\n",
        "\n",
        "output.clear()\n",
        "os.chdir(\"/content/drive/My Drive/\"+path)\n",
        "\n",
        "!pwd\n",
        "!ls -l -a --block-size=M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/#Pengajaran Genap 2021-2022/ASD For Me/MyApp/MyFP\n",
            "total 10M\n",
            "-rw------- 1 root root 1M May 16 13:55 db_kamus_kataYgDiTambahkanManual.bak.txt\n",
            "-rw------- 1 root root 1M May 17 05:44 db_kamus_kataYgDiTambahkanManual.txt\n",
            "drwx------ 2 root root 1M May 16 13:55 dok\n",
            "-rw------- 1 root root 1M May 31 08:35 .env\n",
            "-rw------- 1 root root 3M May 22 12:58 Indonesian_Manually_Tagged_Corpus2.tsv\n",
            "-rw------- 1 root root 1M May 16 13:55 kamusEng.txt\n",
            "-rw------- 1 root root 1M May 22 12:58 mygrammar.cfg\n",
            "-rw------- 1 root root 1M May 16 13:55 myKBBI_tambahan.txt\n",
            "-rw------- 1 root root 5M May 16 13:55 myKBBI.txt\n",
            "-rw------- 1 root root 1M May 16 13:55 namaBulan.txt\n",
            "-rw------- 1 root root 1M May 16 13:55 namaKota.txt\n",
            "-rw------- 1 root root 1M May 16 13:55 namaNegara.txt\n",
            "drwx------ 8 root root 1M May 31 16:10 parsetree-search\n",
            "-rw------- 1 root root 1M May 17 07:37 spam.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Buatlah token dengan Sign-Up atau register ke htpps://dashboard.ngrok.com/auth\n",
        "# get token dari keduanya, lalu masukkan pada kode di bawah ini, aktifkan kodenya lalu jalankan, lalu hide kembali token anda\n",
        "\n",
        "# %%file ./.env\n",
        "NGROK_AUTH_TOKEN = \"29WLM5lBxIJRG0DeHUnWqDDMLzL_BUtxMMm9xFjZhfWXaKFz\""
      ],
      "metadata": {
        "id": "hKUbDMBEr2YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalasi Lib.\n",
        "!pip install python-decouple\n",
        "!pip install pyngrok --quiet\n",
        "!pip install flask\n",
        "!pip install flask_cors\n",
        "!pip install db-sqlite3\n",
        "!pip install freeport\n",
        "!pip install cx_Oracle\n",
        "!pip install flaskcode\n",
        "!pip install autocorrect\n",
        "output.clear()\n",
        "\n",
        "# get token yang dihiden dalam file *.env\n",
        "from decouple import config\n",
        "NGROK_AUTH_TOKEN = config('NGROK_AUTH_TOKEN',default='')"
      ],
      "metadata": {
        "id": "ontcfyG7c4DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Run \"Web App\" dgn tunnel"
      ],
      "metadata": {
        "id": "1qOAU7p0s70X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Edit file app.py"
      ],
      "metadata": {
        "id": "OQW1GxjtdvQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%file ./parsetree-search/templates/fp_index2.html\n",
        "{% extends \"extends/base.html\" %}\n",
        "{% block title %}\n",
        "    <title>Web Data App</title>\n",
        "{% endblock title %}\n",
        "{{ self.title() }}\n",
        "    Home\n",
        "{{ self.title() }}\n",
        "<button onclick=\"window.location.href='/'\" class=\"btn btn-outline btn-rounded btn-info\">\n",
        "    <i class=\"ti-arrow-left m-l-5\"></i>\n",
        "    <span>Back Home</span>\n",
        "</button> Project 1\n",
        "\n",
        "{{ self.title() }}\n",
        "    Project 1\n",
        "\n",
        "{% block content %}\n",
        "\n",
        "\t<div class=\"container\">\n",
        "      <div class=\"row\">\n",
        "        <div class=\"col-sm\">\n",
        "            <form action=\"{{ url_for('fppredict')}}\" method=\"POST\">\n",
        "        \t\t<p>Masukkan kalimat atau paragraf</p>\n",
        "        \t\t<!-- <input type=\"text\" name=\"comment\"/> -->\n",
        "        \t\t<textarea class=\"form-control\" name=\"message\" rows=\"4\">{{ request.form['message'] }}</textarea>\n",
        "\n",
        "        \t\t<br/>\n",
        "\n",
        "        \t\t<input type=\"submit\" class=\"btn-info\" value=\"ParseTree_n_GetTypo\">\n",
        "\n",
        "\t        </form>\n",
        "        </div>\n",
        "        <!-- <br/>\n",
        "        <br/>\n",
        "        <div class=\"col-sm\">\n",
        "            {% if prediction is defined %}\n",
        "             <p style=\"color:blue;font-size:20;text-align: left;\"><b>Hasil Prediksi (Spam/Not a Spam):</b></p>\n",
        "        \t <div class=\"results\">\n",
        "\n",
        "            \t{% if prediction == 1%}\n",
        "            \t<h2 style=\"color:red;\">Spam</h2>\n",
        "            \t{% elif prediction == 0%}\n",
        "            \t<h2 style=\"color:blue;\">Not a Spam (It is a Ham)</h2>\n",
        "            \t{% endif %}\n",
        "\n",
        "        \t</div>\n",
        "        \t{% endif %}\n",
        "        </div> -->\n",
        "        <br/>\n",
        "        <br/>\n",
        "        <div class=\"col-sm\">\n",
        "            {% if tree is defined %}\n",
        "\n",
        "             <p style=\"color:blue;font-size:20;text-align: left;\"><b>Hasil ParseTree:</b></p>\n",
        "        \t <div class=\"results\">\n",
        "                {% autoescape false %}\n",
        "            \t<pre>{{ tree }}</pre>\n",
        "                {% endautoescape %}\n",
        "\n",
        "        \t</div>\n",
        "\n",
        "        \t{% endif %}\n",
        "        </div>\n",
        "        <br/>\n",
        "        <br/>\n",
        "        <div class=\"col-sm\">\n",
        "            {% if typo is defined %}\n",
        "             <p style=\"color:blue;font-size:20;text-align: left;\"><b>Hasil GetTypo:</b></p>\n",
        "        \t <div class=\"results\">\n",
        "            \t<h2 style=\"color:red;\">{{ typo }}</h2>\n",
        "        \t</div>\n",
        "        \t{% endif %}\n",
        "        </div>\n",
        "      </div>\n",
        "    </div>\n",
        "\n",
        "{% endblock content %}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdbtTbzx3PJK",
        "outputId": "58b1c5fd-b106-4264-c0a9-de7434b799ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./parsetree-search/templates/fp_index2.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./parsetree-search/templates/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmSiqL7D4Qs2",
        "outputId": "4b787c0a-138a-4581-8b99-e6d203df1282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "404.html\t  extends\t\t   kode_cek_flask_reg.html\n",
            "500.html\t  fp_index2.html\t   login.html\n",
            "base_upload.html  fp_result.html\t   MybigdataApps.html\n",
            "bdc.html\t  getsuhu_tipe_dua.html    MybigdataAppsNonPySpark.html\n",
            "bigdataApps.html  getsuhu_tipe_empat.html  MybigdataAppsPySpark.html\n",
            "biz2.html\t  getsuhu_tipe_satu.html   register.html\n",
            "biz.html\t  getsuhu_tipe_tiga.html   twit.html\n",
            "bli.html\t  include\t\t   twity.html\n",
            "charts.html\t  index.html\t\t   upload.html\n",
            "dashboard.html\t  kode_cek_flask.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/susanli2016/SMS-Message-Spam-Detector/master/spam.csv -P ./parsetree-search"
      ],
      "metadata": {
        "id": "YFymAx7e52Lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b8c952-0c10-446e-9c2e-e62f206858da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-31 16:42:08--  https://raw.githubusercontent.com/susanli2016/SMS-Message-Spam-Detector/master/spam.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503673 (492K) [text/plain]\n",
            "Saving to: ‘./parsetree-search/spam.csv.16’\n",
            "\n",
            "\rspam.csv.16           0%[                    ]       0  --.-KB/s               \rspam.csv.16         100%[===================>] 491.87K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-05-31 16:42:09 (12.2 MB/s) - ‘./parsetree-search/spam.csv.16’ saved [503673/503673]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file ./parsetree-search/app.py\n",
        "\n",
        "from flask import Flask,render_template,flash, Response, redirect,url_for,session,logging,request,jsonify,make_response\n",
        "import sqlite3\n",
        "from flask_cors import CORS\n",
        "import os\n",
        "import threading\n",
        "from pyngrok import ngrok\n",
        "import numpy as np\n",
        "import pandas\n",
        "from pandas import DataFrame\n",
        "import os.path\n",
        "import re\n",
        "import string\n",
        "import datetime\n",
        "import json\n",
        "from flask import send_file\n",
        "from io import BytesIO\n",
        "\n",
        "import cx_Oracle      # We are an Oracle shop, and this changes some things\n",
        "import csv\n",
        "# import StringIO       # allows you to store response object in memory instead of on disk\n",
        "from io import StringIO\n",
        "# from flask import make_response # Necessary imports, should be obvious\n",
        "\n",
        "import flaskcode\n",
        "\n",
        "import nltk\n",
        "from autocorrect import spell\n",
        "from gensim.summarization import summarize as g_sumn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "os.environ[\"FLASK_ENV\"] = \"development\"\n",
        "app = Flask(__name__, static_folder='static')\n",
        "\n",
        "CORS(app, resources=r'/api/*')\n",
        "\n",
        "# app.debug = False\n",
        "app.secret_key = 'key_app'\n",
        "\n",
        "# app = Flask(__name__)\n",
        "app.config.from_object(flaskcode.default_config)\n",
        "# app.config['FLASKCODE_RESOURCE_BASEPATH'] = '/path/to/resource/folder'\n",
        "app.config['FLASKCODE_RESOURCE_BASEPATH'] = './parsetree-search'\n",
        "app.register_blueprint(flaskcode.blueprint, url_prefix='/vs')\n",
        "\n",
        "def semua(args):\n",
        "    import pandas as pd\n",
        "    from nltk import Tree\n",
        "    dataset = pd.read_table('Indonesian_Manually_Tagged_Corpus2.tsv', header=None, names=['words','tags'])\n",
        "    #dataset.head(10)\n",
        "\n",
        "    #Tulis kode untuk hitung frequency tiap jenis tag\n",
        "    counted = dataset['tags'].value_counts()\n",
        "\n",
        "    #Tulis kode untuk mengoutputkan 10 most frequent tags\n",
        "    #print('10 most frequent tags:', counted.head(10), sep='\\n')\n",
        "\n",
        "    #Tulis kode untuk mengoutputkan 10 most frequent words given NN tag\n",
        "    #NN_tagged = dataset[dataset['tags']=='NN']\n",
        "    #NN_counted = NN_tagged['words'].value_counts()\n",
        "    #print('\\n10 most frequent words given NN tag:', NN_counted.head(10), sep='\\n')\n",
        "\n",
        "    # #Tulis kode untuk mengoutputkan 5 kata yang memiliki tag lebih dari 1, beserta tag2nya.\n",
        "    # grouped_by_word = dataset.groupby('words')['tags'].unique()\n",
        "    # word_and_mt1_tags = grouped_by_word[grouped_by_word.apply(lambda x: len(x)>1)]\n",
        "    # print('\\nWords and more than 1 tags with all tags:', word_and_mt1_tags.sample(5), sep='\\n')\n",
        "\n",
        "    import nltk\n",
        "    from nltk import hmm\n",
        "    def c_list_of_sentences(low, sep):\n",
        "        sentence = []\n",
        "        sentences = []\n",
        "        for word in low:\n",
        "            sentence.append(word)\n",
        "            if word == sep:\n",
        "                sentences.append(sentence)\n",
        "                sentence = []\n",
        "        return sentences\n",
        "\n",
        "    #train_data adalah list yang menampung semua kalimat dengan format di atas\n",
        "    #Tulis kode untuk transform kalimat ke format [('kata1','tag1'),('kata2','tag2'),('kata3','tag3')]\n",
        "    #lalu simpan semua kalimat dalam list train_data\n",
        "\n",
        "    list_of_words = dataset.to_records(index=False).tolist()\n",
        "    sep = ('.', 'Z')\n",
        "\n",
        "    train_data = c_list_of_sentences(list_of_words, sep)\n",
        "\n",
        "    trainer=hmm.HiddenMarkovModelTrainer()\n",
        "    tagger=trainer.train_supervised(train_data)\n",
        "\n",
        "    grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
        "    parser = nltk.ChartParser(grammar1)\n",
        "\n",
        "    def get_missing_words(grammar, tokens):\n",
        "        \"\"\"\n",
        "        Find list of missing tokens not covered by grammar\n",
        "        \"\"\"\n",
        "        missing = [tok for tok in tokens\n",
        "                  if not grammar._lexical_index.get(tok)]\n",
        "        return missing\n",
        "    def parsetree (args):\n",
        "        str_hasil = \"\"\n",
        "        # cek_kata_diluar_grammar = get_missing_words(grammar1,args.split())\n",
        "        cek_kata_diluar_grammar = \"\"\n",
        "        if(len(cek_kata_diluar_grammar)==0):\n",
        "          sent = args.split()\n",
        "          # print(sent)\n",
        "\n",
        "          tagged_text = tagger.tag(sent)\n",
        "          #pos_tags = [pos for (token,pos) in tagged_text]\n",
        "          # print (tagged_text)\n",
        "\n",
        "          temp = \"\"\n",
        "\n",
        "          #for tree in parser.parse(sent):\n",
        "            #if tree != temp:\n",
        "              #if str(tree.pretty_print()) is not None:\n",
        "                #str_hasil+=str(tree.pretty_print())\n",
        "            #temp = tree\n",
        "\n",
        "\n",
        "\n",
        "          if(temp==''):\n",
        "            sentence = tagged_text\n",
        "            pattern = \"\"\"NP: {<DT>?<JJ>*<NN>}\n",
        "            VBD: {<VBD>}\n",
        "            IN: {<IN>}\"\"\"\n",
        "            NPChunker = nltk.RegexpParser(pattern)\n",
        "            result = NPChunker.parse(sentence)\n",
        "            if result is not None:\n",
        "              str_hasil+=str(result)\n",
        "            Tree.fromstring(str(result)).pretty_print()\n",
        "\n",
        "            temp = result\n",
        "          return temp\n",
        "\n",
        "    return str(parsetree(args))\n",
        "\n",
        "@app.route('/fphome')\n",
        "def fphome():\n",
        "    return render_template('fp_index2.html')\n",
        "\n",
        "@app.route('/fppredict',methods=['POST'])\n",
        "def fppredict():\n",
        "    import numpy as np\n",
        "    # import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "    import os.path\n",
        "\n",
        "    #BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "    #url = os.path.join(BASE_DIR, \"spam.csv\")\n",
        "\n",
        "    BASE_DIR = os.getcwd()+'/parsetree-search'\n",
        "    url = os.path.join(BASE_DIR, \"spam.csv\")\n",
        "\n",
        "\n",
        "    df= pd.read_csv(url, encoding=\"latin-1\")\n",
        "    #df= pd.read_csv(url)\n",
        "    #df = pd.read_csv(url)\n",
        "    df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
        "\n",
        "    # Features and Labels\n",
        "    df['label'] = df['class'].map({'ham': 0, 'spam': 1})\n",
        "    X = df['message']\n",
        "    y = df['label']\n",
        "\n",
        "    # Extract Feature With CountVectorizer\n",
        "\n",
        "    cv = CountVectorizer()\n",
        "\n",
        "    X = cv.fit_transform(X) # Fit the Data\n",
        "\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "    #Naive Bayes Classifier\n",
        "\n",
        "    from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "    clf = MultinomialNB()\n",
        "    clf.fit(X_train,y_train)\n",
        "    clf.score(X_test,y_test)\n",
        "    #Alternative Usage of Saved Model\n",
        "    # joblib.dump(clf, 'NB_spam_model.pkl')\n",
        "    # NB_spam_model = open('NB_spam_model.pkl','rb')\n",
        "\n",
        "    # clf = joblib.load(NB_spam_model)\n",
        "\n",
        "    if request.method == 'POST':\n",
        "        message = request.form['message']\n",
        "        data = [message]\n",
        "        vect = cv.transform(data).toarray()\n",
        "        my_prediction = clf.predict(vect)\n",
        "        hasil_tree_sample = semua(message)\n",
        "\n",
        "    def get_missing_words(grammar, tokens):\n",
        "        \"\"\"\n",
        "        Find list of missing tokens not covered by grammar\n",
        "        \"\"\"\n",
        "        missing = [tok for tok in tokens\n",
        "                  if not grammar._lexical_index.get(tok)]\n",
        "        return missing\n",
        "\n",
        "    grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
        "    parser = nltk.ChartParser(grammar1)\n",
        "\n",
        "    message = request.form['message']\n",
        "    hasil_typo_sample = get_missing_words(grammar1, message.split())\n",
        "\n",
        "    #return render_template('fp_result.html',prediction = my_prediction)\n",
        "    return render_template('fp_index2.html',prediction = my_prediction, tree = hasil_tree_sample, typo = hasil_typo_sample)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return redirect(url_for(\"login\"))\n",
        "    #return \"Hello Flask IoT Simulator Using Python - Statistika Kelas B! :D\"\n",
        "\n",
        "@app.route(\"/chart\")\n",
        "def chart():\n",
        "    BASE_DIR = os.getcwd()+'/parsetree-search'\n",
        "    path_data = os.path.join(BASE_DIR, \"data/data.csv\")\n",
        "\n",
        "    df = pandas.read_csv(path_data)\n",
        "    days = np.unique(df['day'])\n",
        "\n",
        "    allValues = {}\n",
        "    for day in days:\n",
        "        df_ = df.query('day==' + str(day))\n",
        "        labels = df_['hour']\n",
        "        #print(labels)\n",
        "        values_dewp = df_['DEWP']\n",
        "        values_temp = df_['TEMP']\n",
        "        values1 = [values_dewp, values_temp, labels]\n",
        "        allValues[day] = values1\n",
        "    return render_template('charts.html', days = days, values=allValues)\n",
        "\n",
        "@app.route(\"/ptree\",methods=[\"GET\", \"POST\"])\n",
        "def ptree():\n",
        "  tree_sample = \"\"\"\n",
        "                S\n",
        "      __________|_________________________\n",
        "    SUB         |        PEL             KET\n",
        "     |          |         |               |\n",
        "    FNOM       PRE      FPREP           FPREP\n",
        "  ___|____      |     ____|_____      ____|______\n",
        " NN  CC   NN    VB   IN         NN   IN         NNP\n",
        " |   |    |     |    |          |    |           |\n",
        "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  return tree_sample.replace(\" \",\"&nbsp&nbsp\").replace(\"\\n\",\"<br>\")\n",
        "\n",
        "@app.route(\"/login\",methods=[\"GET\", \"POST\"])\n",
        "def login():\n",
        "  conn = connect_db()\n",
        "  db = conn.cursor()\n",
        "  msg = \"\"\n",
        "  if request.method == \"POST\":\n",
        "      mail = request.form[\"mail\"]\n",
        "      passw = request.form[\"passw\"]\n",
        "\n",
        "      rs = db.execute(\"SELECT * FROM user WHERE Mail=\\'\"+ mail +\"\\'\"+\" AND Password=\\'\"+ passw+\"\\'\" + \" LIMIT 1\")\n",
        "\n",
        "      conn.commit()\n",
        "\n",
        "      hasil = []\n",
        "      for v_login in rs:\n",
        "          hasil.append(v_login)\n",
        "\n",
        "      if hasil:\n",
        "          session['name'] = v_login[3]\n",
        "          return redirect(url_for(\"fphome\"))\n",
        "      else:\n",
        "          msg = \"Masukkan Username (Email) dan Password dgn Benar!\"\n",
        "\n",
        "  return render_template(\"login.html\", msg = msg)\n",
        "\n",
        "@app.route(\"/register\", methods=[\"GET\", \"POST\"])\n",
        "def register():\n",
        "  conn = connect_db()\n",
        "  db = conn.cursor()\n",
        "  msg = \"\"\n",
        "  if request.method == \"POST\":\n",
        "      mail = request.form['mail']\n",
        "      uname = request.form['uname']\n",
        "      passw = request.form['passw']\n",
        "\n",
        "      #cek apakah ada yg sudah menggunakan email tersebut\n",
        "      rs = db.execute(\"SELECT * FROM user WHERE Mail=\\'\"+ mail +\"\\'\" + \" LIMIT 1\")\n",
        "\n",
        "      hasil = []\n",
        "      for v_login in rs:\n",
        "          hasil.append(v_login)\n",
        "\n",
        "      if hasil:\n",
        "          #msg = \"Masukkan Username (Email) Lain, karena Email trsbt sudah digunakan oleh user Lainnya\"\n",
        "          msg = \"Email trsbt sudah digunakan oleh user Lainnya\"\n",
        "          conn.commit()\n",
        "          db.close()\n",
        "          conn.close()\n",
        "      else:\n",
        "          if (bool(mail and not mail.isspace()) and bool(uname and not uname.isspace()) and bool(passw and not passw.isspace())):\n",
        "              cmd = \"insert into user(Mail, Password,Name,Level) values('{}','{}','{}','{}')\".format(mail,passw,uname,'1')\n",
        "              conn.execute(cmd)\n",
        "              conn.commit()\n",
        "              db.close()\n",
        "              conn.close()\n",
        "              #return redirect(url_for(\"login\"))\n",
        "              msg = \"Masukkan Username (Email) dan Password dgn Benar!\"\n",
        "              return render_template(\"login.html\", msg = msg)\n",
        "          else:\n",
        "              msg = \"Lengkapi isian data Anda!\"\n",
        "  return render_template(\"register.html\", msg = msg)\n",
        "\n",
        "def connect_db():\n",
        "    # import os.path\n",
        "    # BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "    BASE_DIR = os.getcwd()+'/parsetree-search'\n",
        "    db_path = os.path.join(BASE_DIR, \"data.db\")\n",
        "    return sqlite3.connect(db_path)\n",
        "\n",
        "@app.errorhandler(404)\n",
        "def page_not_found(error):\n",
        "    return render_template(\"404.html\")\n",
        "\n",
        "@app.errorhandler(500)\n",
        "def internal_server_error(error):\n",
        "    return render_template(\"500.html\")\n",
        "\n",
        "@app.route('/getsuhu_tipe_satu', methods=[\"GET\", \"POST\"])\n",
        "def getsuhu_tipe_satu():\n",
        "\n",
        "    if 'name' in session:\n",
        "        name = session['name']\n",
        "    else:\n",
        "        name = 'Guest'\n",
        "\n",
        "    from datetime import datetime\n",
        "    import pytz\n",
        "    Date = str(datetime.today().astimezone(pytz.timezone('Asia/Jakarta')).strftime('%d-%m-%Y %H:%M:%S'))\n",
        "\n",
        "    conn = connect_db()\n",
        "    db = conn.cursor()\n",
        "\n",
        "    c = db.execute(\"\"\" SELECT * FROM  data_suhu_dll_api_openweathermap \"\"\")\n",
        "\n",
        "    mydata = c.fetchall()\n",
        "    for x in c.fetchall():\n",
        "        name_v=x[0]\n",
        "        data_v=x[1]\n",
        "        break\n",
        "\n",
        "    hasil = []\n",
        "    for v_login in c:\n",
        "        hasil.append(v_login)\n",
        "\n",
        "    conn.commit()\n",
        "    db.close()\n",
        "    conn.close()\n",
        "\n",
        "    return render_template(\"getsuhu_tipe_satu.html\", header = mydata)\n",
        "\n",
        "@app.route('/unduh_data_tipe_satu/', methods=[\"GET\"])\n",
        "def dw_data_tipe_satu():\n",
        "    # name = request.args.get('name')\n",
        "    conn = connect_db()\n",
        "    db = conn.cursor()\n",
        "\n",
        "    c = db.execute(\"SELECT * FROM data_suhu_dll_api_openweathermap\")\n",
        "\n",
        "    # def export(load_file_id):\n",
        "    si = StringIO()\n",
        "    cw = csv.writer(si)\n",
        "\n",
        "    rows = c.fetchall()\n",
        "    cw.writerow([i[0] for i in c.description])\n",
        "    cw.writerows(rows)\n",
        "    response = make_response(si.getvalue())\n",
        "    response.headers['Content-Disposition'] = 'attachment; filename=data.csv'\n",
        "    response.headers[\"Content-type\"] = \"text/csv\"\n",
        "\n",
        "    conn.commit()\n",
        "    db.close()\n",
        "    conn.close()\n",
        "\n",
        "    return response\n",
        "\n",
        "@app.route('/logout')\n",
        "def logout():\n",
        "   # remove the name from the session if it is there\n",
        "   session.pop('name', None)\n",
        "   return redirect(url_for('index'))\n",
        "\n",
        "@app.route(\"/p2021\",methods=[\"GET\", \"POST\"])\n",
        "def p2021():\n",
        "  conn = connect_db()\n",
        "  db = conn.cursor()\n",
        "  msg = \"\"\n",
        "\n",
        "  return render_template(\"docs/assets/index.html\", msg = msg)\n",
        "\n",
        "# Start the Flask server in a new thread\n",
        "threading.Thread(target=app.run, kwargs={\"use_reloader\": False}).start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Hursh0S2rG",
        "outputId": "9e358ace-6a37-4d7e-a1db-17a6f0099161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./parsetree-search/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cara run Web App\n",
        "!echo yes | freeport 5000\n",
        "output.clear()\n",
        "get_ipython().system_raw('python ./parsetree-search/app.py --host=0.0.0.0 --port=5000 &')"
      ],
      "metadata": {
        "id": "SJyzRdmstMHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "#terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "#Setting the authtoken (optional)\n",
        "#Get your authtoken from htpps://dashboard.ngrok.com/auth\n",
        "# NGROK_AUTH_TOKEN_ALT = \"\"\n",
        "# !ngrok tcp 5000\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "ngrok.connect(5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMD3W1QJtRu9",
        "outputId": "450d80c6-f1cc-414d-8231-dfebf5296278"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"http://ab32-35-185-31-224.ngrok.io\" -> \"http://localhost:5000\">"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contoh ilustrasi Hasil ParseTree dan Get Typo:\n",
        "![]( https://docs.google.com/uc?export=download&id=1X7qldS1-JckrkpOVqZQLH0DzqOUczHPS)"
      ],
      "metadata": {
        "id": "pUy2VO2vQJ3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start Buat Koding FP (Dgn C/C++ || Java || Python)"
      ],
      "metadata": {
        "id": "FUgkQb62Ee1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Koding ParseTree disini prototype-nya sebelum dipindahkan ke Web App |\n",
        "# (ambil koding dari solusi soal UTS no.2 + ambil dari koding dasar dari link: https://bit.ly/3w548Eb lalu modifikasi untuk get \"isi abstrak dok\")\n",
        "# yg di ParseTree-kan cukup dari kalimat-kalimat yang ada pada abstrak indo saja atau abtract yg english saja\n",
        "\n",
        "# ..\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bH8GVnTWDByo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### untuk contoh koding ParseTree"
      ],
      "metadata": {
        "id": "lasDl0K5tyed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1n4DjHpxXWFbKeH8D2oK7sYY5RDy9n_6b\n",
        "!gdown 1V-vhHTJ5kaXEOIPEjxwa39nOXslsVMdU"
      ],
      "metadata": {
        "id": "20gjixwDI14b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f9b285-c395-458a-a0ce-0033d3b09d3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n4DjHpxXWFbKeH8D2oK7sYY5RDy9n_6b\n",
            "To: /content/drive/MyDrive/#Pengajaran Genap 2021-2022/ASD For Me/MyApp/MyFP/Indonesian_Manually_Tagged_Corpus2.tsv\n",
            "100% 2.48M/2.48M [00:00<00:00, 118MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1V-vhHTJ5kaXEOIPEjxwa39nOXslsVMdU\n",
            "To: /content/drive/MyDrive/#Pengajaran Genap 2021-2022/ASD For Me/MyApp/MyFP/mygrammar.cfg\n",
            "100% 238k/238k [00:00<00:00, 54.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk import Tree\n",
        "dataset = pd.read_table('Indonesian_Manually_Tagged_Corpus2.tsv', header=None, names=['words','tags'])\n",
        "#dataset.head(10)\n",
        "\n",
        "#Tulis kode untuk hitung frequency tiap jenis tag\n",
        "counted = dataset['tags'].value_counts()\n",
        "\n",
        "#Tulis kode untuk mengoutputkan 10 most frequent tags\n",
        "#print('10 most frequent tags:', counted.head(10), sep='\\n')\n",
        "\n",
        "#Tulis kode untuk mengoutputkan 10 most frequent words given NN tag\n",
        "#NN_tagged = dataset[dataset['tags']=='NN']\n",
        "#NN_counted = NN_tagged['words'].value_counts()\n",
        "#print('\\n10 most frequent words given NN tag:', NN_counted.head(10), sep='\\n')\n",
        "\n",
        "# #Tulis kode untuk mengoutputkan 5 kata yang memiliki tag lebih dari 1, beserta tag2nya.\n",
        "# grouped_by_word = dataset.groupby('words')['tags'].unique()\n",
        "# word_and_mt1_tags = grouped_by_word[grouped_by_word.apply(lambda x: len(x)>1)]\n",
        "# print('\\nWords and more than 1 tags with all tags:', word_and_mt1_tags.sample(5), sep='\\n')\n",
        "\n",
        "import nltk\n",
        "from nltk import hmm\n",
        "\n",
        "# Fungsi membuat list of list of tuple\n",
        "# low: List of Words\n",
        "# sep: separator (pemisah dalam kalimat, titik)\n",
        "def c_list_of_sentences(low, sep):\n",
        "    sentence = []\n",
        "    sentences = []\n",
        "    for word in low:\n",
        "        sentence.append(word)\n",
        "        if word == sep:\n",
        "            sentences.append(sentence)\n",
        "            sentence = []\n",
        "    return sentences\n",
        "\n",
        "#train_data adalah list yang menampung semua kalimat dengan format di atas\n",
        "#Tulis kode untuk transform kalimat ke format [('kata1','tag1'),('kata2','tag2'),('kata3','tag3')]\n",
        "#lalu simpan semua kalimat dalam list train_data\n",
        "\n",
        "list_of_words = dataset.to_records(index=False).tolist()\n",
        "sep = ('.', 'Z')\n",
        "\n",
        "train_data = c_list_of_sentences(list_of_words, sep)\n",
        "\n",
        "trainer=hmm.HiddenMarkovModelTrainer()\n",
        "tagger=trainer.train_supervised(train_data)\n",
        "\n",
        "grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
        "parser = nltk.ChartParser(grammar1)\n",
        "\n",
        "def get_missing_words(grammar, tokens):\n",
        "    \"\"\"\n",
        "    Find list of missing tokens not covered by grammar\n",
        "    \"\"\"\n",
        "    missing = [tok for tok in tokens\n",
        "               if not grammar._lexical_index.get(tok)]\n",
        "    return missing\n",
        "\n",
        "\n",
        "def parsetree (args):\n",
        "    str_hasil = \"\"\n",
        "    cek_kata_diluar_grammar = get_missing_words(grammar1,args.split())\n",
        "    if(len(cek_kata_diluar_grammar)==0):\n",
        "      sent = args.split()\n",
        "      # print(sent)\n",
        "\n",
        "      tagged_text = tagger.tag(sent)\n",
        "      pos_tags = [pos for (token,pos) in tagged_text]\n",
        "      # print (tagged_text)\n",
        "\n",
        "      temp = \"\"\n",
        "\n",
        "      for tree in parser.parse(sent):\n",
        "        if tree != temp:\n",
        "          if str(tree.pretty_print()) is not None:\n",
        "            str_hasil+=str(tree.pretty_print())\n",
        "        temp = tree\n",
        "\n",
        "\n",
        "\n",
        "      if(temp==''):\n",
        "        sentence = tagged_text\n",
        "        pattern = \"\"\"NP: {<DT>?<JJ>*<NN>}\n",
        "        VBD: {<VBD>}\n",
        "        IN: {<IN>}\"\"\"\n",
        "        NPChunker = nltk.RegexpParser(pattern)\n",
        "        result = NPChunker.parse(sentence)\n",
        "        if result is not None:\n",
        "          str_hasil+=str(result)\n",
        "        Tree.fromstring(str(result)).pretty_print()\n",
        "\n",
        "        temp = result\n",
        "\n",
        "\n",
        "\n",
        "      return temp\n",
        "    else:\n",
        "      str_hasil += \"Terdapat kata yang tidak ada pada grammer = \" + str(cek_kata_diluar_grammar) + \"\\n\"\n",
        "      # print(\"Terdapat kata yang tidak ada pada grammer = \", cek_kata_diluar_grammar)\n",
        "      for term_in in cek_kata_diluar_grammar:\n",
        "        args = args.replace(term_in,\"\")\n",
        "\n",
        "      sent = args.split()\n",
        "      # print(sent)\n",
        "\n",
        "      tagged_text = tagger.tag(sent)\n",
        "      pos_tags = [pos for (token,pos) in tagged_text]\n",
        "      # print (tagged_text)\n",
        "\n",
        "      temp = \"\"\n",
        "\n",
        "      for tree in parser.parse(sent):\n",
        "        if tree != temp:\n",
        "          if str(tree.pretty_print()) is not None:\n",
        "            str_hasil += str(tree.pretty_print())\n",
        "        temp = tree\n",
        "\n",
        "      if(temp==''):\n",
        "        sentence = tagged_text\n",
        "        pattern = \"\"\"NP: {<DT>?<JJ>*<NN>}\n",
        "        VBD: {<VBD>}\n",
        "        IN: {<IN>}\"\"\"\n",
        "        NPChunker = nltk.RegexpParser(pattern)\n",
        "        result = NPChunker.parse(sentence)\n",
        "        if result is not None:\n",
        "          str_hasil += str(result)\n",
        "        Tree.fromstring(str(result)).pretty_print()\n",
        "\n",
        "      return str_hasil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#parsetree(\"saya membaca buku tiga halaman di halaman sekolah\")\n",
        "#parsetree(\"kami bangkit bersama dengan keterpurukan\")\n",
        "# temp = parsetree(\"ibu dan ayah pergi ke pasar di Jakarta\")\n",
        "\n",
        "toText = parsetree(\"ibu dan ayah pergi ke pasar di Jakarta\")\n",
        "# toText = parsetree(\"banjir sudah melanda kota Jakarta tiga tahun silam\")\n",
        "# parsetree(\"kami bangkit bersama dengan keterpurukan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3yusmXaI0TR",
        "outputId": "b4edd1d0-28e8-4531-b960-07bdd8348cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                S                                    \n",
            "      __________|_________________________            \n",
            "    SUB         |        PEL             KET         \n",
            "     |          |         |               |           \n",
            "    FNOM       PRE      FPREP           FPREP        \n",
            "  ___|____      |     ____|_____      ____|______     \n",
            " NN  CC   NN    VB   IN        NNP   IN         NNP  \n",
            " |   |    |     |    |          |    |           |    \n",
            "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
            "\n",
            "                S                                    \n",
            "      __________|_________________________            \n",
            "    SUB         |        PEL             KET         \n",
            "     |          |         |               |           \n",
            "    FNOM       PRE      FPREP           FPREP        \n",
            "  ___|____      |     ____|_____      ____|______     \n",
            " NN  CC   NN    VB   IN        NNP   IN         NNP  \n",
            " |   |    |     |    |          |    |           |    \n",
            "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
            "\n",
            "                S                                    \n",
            "      __________|_________________________            \n",
            "    SUB         |        PEL             KET         \n",
            "     |          |         |               |           \n",
            "    FNOM       PRE      FPREP           FPREP        \n",
            "  ___|____      |     ____|_____      ____|______     \n",
            " NN  CC   NN    VB   IN         NN   IN         NNP  \n",
            " |   |    |     |    |          |    |           |    \n",
            "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
            "\n",
            "                S                                    \n",
            "      __________|_________________________            \n",
            "    SUB         |        PEL             KET         \n",
            "     |          |         |               |           \n",
            "    FNOM       PRE      FPREP           FPREP        \n",
            "  ___|____      |     ____|_____      ____|______     \n",
            " NN  CC   NN    VB   IN         NN   IN         NNP  \n",
            " |   |    |     |    |          |    |           |    \n",
            "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CREATE VIRTUAL DISPLAY ###\n",
        "!pip install ghostscript\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0."
      ],
      "metadata": {
        "id": "MeNts1zz2AOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsetree(\"Buku Pedoman Akademik FILKOM Universitas Brawijaya merupakan suatu kebutuhan informasi akademik yang cukup penting, dan juga buku penunjang pembelajaran seperti Free e-Book bagi para mahasiswa\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "EGlEnc2LhSnW",
        "outputId": "c3ee36b6-a0e0-4d9e-dc95-ef2688bd639a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terdapat kata yang tidak ada pada grammer =  ['Akademik', 'FILKOM', 'Brawijaya', 'akademik', 'penting,', 'Free', 'e-Book']\n",
            "['Buku', 'Pedoman', 'Universitas', 'merupakan', 'suatu', 'kebutuhan', 'informasi', 'yang', 'cukup', 'dan', 'juga', 'buku', 'penunjang', 'pembelajaran', 'seperti', 'bagi', 'para', 'mahasiswa']\n",
            "[('Buku', 'NN'), ('Pedoman', 'NNP'), ('Universitas', 'NNP'), ('merupakan', 'VB'), ('suatu', 'CD'), ('kebutuhan', 'NN'), ('informasi', 'NN'), ('yang', 'SC'), ('cukup', 'RB'), ('dan', 'CC'), ('juga', 'RB'), ('buku', 'NN'), ('penunjang', 'NN'), ('pembelajaran', 'NN'), ('seperti', 'IN'), ('bagi', 'IN'), ('para', 'DT'), ('mahasiswa', 'NN')]\n",
            "                                                                                     S                                                                                                              \n",
            "      _______________________________________________________________________________|_______________________________________________________________________________________________                \n",
            "     |             |             |          |        |       |       |       |       NP        NP           NP         NP        NP             NP           IN        IN            NP             \n",
            "     |             |             |          |        |       |       |       |       |         |            |          |         |              |            |         |        _____|_______        \n",
            "Pedoman/NNP Universitas/NNP merupakan/VB suatu/CD yang/SC cukup/RB dan/CC juga/RB Buku/NN kebutuhan/NN informasi/NN buku/NN penunjang/NN pembelajaran/NN seperti/IN bagi/IN para/DT     mahasiswa/NN\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(toText)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qXMpk9euvMWN",
        "outputId": "ec934f6e-c0c3-4258-9701-07b36466a797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(S\\n  (SUB (FNOM (NN ibu) (CC dan) (NN ayah)))\\n  (PRE (VB pergi))\\n  (PEL (FPREP (IN ke) (NN pasar)))\\n  (KET (FPREP (IN di) (NNP Jakarta))))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import Tree\n",
        "Tree.fromstring(str(toText)).pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKidzkCXTJbH",
        "outputId": "590466f9-a447-447b-da39-ef9840812b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                S                                    \n",
            "      __________|_________________________            \n",
            "    SUB         |        PEL             KET         \n",
            "     |          |         |               |           \n",
            "    FNOM       PRE      FPREP           FPREP        \n",
            "  ___|____      |     ____|_____      ____|______     \n",
            " NN  CC   NN    VB   IN         NN   IN         NNP  \n",
            " |   |    |     |    |          |    |           |    \n",
            "ibu dan  ayah pergi  ke       pasar  di       Jakarta\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install treelib\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "KNZQg-krUmpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from treelib import Node, Tree\n",
        "\n",
        "\n",
        "lst = [\"S\", [\"NP\", [\"DT\", \"the\"], [\"NN\", \"dog\"]], [\"VP\", [\"Vt\", \"saw\"], [\"NP\", [\"NP\", [\"DT\", \"the\"], [\"NN\", \"man\"]],\n",
        "                                                                   [\"PP\", [\"P\", \"with\"],\n",
        "                                                                    [\"NP\", [\"DT\", \"the\"], [\"NN\", \"telescope\"]]]]]]\n",
        "\n",
        "# lst = [('ibu', 'NN'), ('dan', 'CC'), ('ayah', 'NN'), ('pergi', 'VB'), ('ke', 'IN'), ('pasar', 'NN'), ('di', 'IN'), ('Jakarta', 'NNP')]\n",
        "\n",
        "root, *tail = lst\n",
        "tree = Tree()\n",
        "node = Node(root)\n",
        "tree.add_node(node)\n",
        "\n",
        "q = [[node, *tail]]\n",
        "while q:\n",
        "    parent, *children = q.pop()\n",
        "    for child in children:\n",
        "        if isinstance(child, list):\n",
        "            head, *tail = child\n",
        "            node = tree.create_node(head, parent=parent)\n",
        "            q.append([node, *tail])\n",
        "        else:\n",
        "            tree.create_node(child, parent=parent)\n",
        "\n",
        "tree.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5GKGeeFUhYu",
        "outputId": "245b2694-13c8-46a4-a75f-09e6160401ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S\n",
            "├── NP\n",
            "│   ├── DT\n",
            "│   │   └── the\n",
            "│   └── NN\n",
            "│       └── dog\n",
            "└── VP\n",
            "    ├── NP\n",
            "    │   ├── NP\n",
            "    │   │   ├── DT\n",
            "    │   │   │   └── the\n",
            "    │   │   └── NN\n",
            "    │   │       └── man\n",
            "    │   └── PP\n",
            "    │       ├── NP\n",
            "    │       │   ├── DT\n",
            "    │       │   │   └── the\n",
            "    │       │   └── NN\n",
            "    │       │       └── telescope\n",
            "    │       └── P\n",
            "    │           └── with\n",
            "    └── Vt\n",
            "        └── saw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Koding \"Typo atau get kata yg tidak ada pada kamus\" disini prototype-nya sebelum dipindahkan ke Web App |\n",
        "# (ambil dari koding dasar dari link: https://bit.ly/3w548Eb lalu modifikasi utk get \"Typo atau get kata yg tidak ada pada kamus\")\n",
        "\n",
        "# ..\n"
      ],
      "metadata": {
        "id": "36PPALRutEQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hi All Great Students"
      ],
      "metadata": {
        "id": "Bnw-pQHfRyZr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvIA1SPUgFuo"
      },
      "source": [
        "Semoga Sukses. Aamiin. :D\n",
        "![]( https://docs.google.com/uc?export=download&id=1vJNmuncRehLc3WCZkFYCU6rRMVTy-w0k)"
      ]
    }
  ]
}